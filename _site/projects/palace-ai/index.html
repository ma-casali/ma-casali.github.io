<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Training an AI to play the Palace Card Game | Matthew Casali</title>
<meta name="generator" content="Jekyll v3.9.5" />
<meta property="og:title" content="Training an AI to play the Palace Card Game" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Training framework using PyTorch to train a neural net to play the card game ‘Palace’ against two other players." />
<meta property="og:description" content="Training framework using PyTorch to train a neural net to play the card game ‘Palace’ against two other players." />
<link rel="canonical" href="http://localhost:4000/projects/palace-ai/" />
<meta property="og:url" content="http://localhost:4000/projects/palace-ai/" />
<meta property="og:site_name" content="Matthew Casali" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2025-12-30T00:00:00-08:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Training an AI to play the Palace Card Game" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2025-12-30T00:00:00-08:00","datePublished":"2025-12-30T00:00:00-08:00","description":"Training framework using PyTorch to train a neural net to play the card game ‘Palace’ against two other players.","headline":"Training an AI to play the Palace Card Game","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/projects/palace-ai/"},"url":"http://localhost:4000/projects/palace-ai/"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Matthew Casali" /><script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>

  <link rel="stylesheet" href="/assets/css/main.css">
  
</head>


<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Matthew Casali</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/">Home</a><a class="page-link" href="/my-a-projects.html">Projects</a><a class="page-link" href="/my-b-music.html">Music</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Training an AI to play the Palace Card Game</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2025-12-30T00:00:00-08:00" itemprop="datePublished">Dec 30, 2025
      </time></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <script type="text/javascript" async="" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<h1 id="the-goal">The Goal</h1>

<p>Since I was taught how to play Palace by my girlfriend, I think my record when playing against her stands at 1 - 49. In order to fix my losing streak, I thought it would be the perfect opportunity to use my experience in developing deep learning models to create an AI Palace player so that I can practice against them and learn about the strategies that they develop.</p>

<h1 id="implementation-of-the-game-rules">Implementation of the game rules</h1>

<p>Focusing only on the output for now, the AI has the following options:</p>

<ol>
  <li><strong>Action Index (0 - 12), (13 - 25), (26 - 38), (39 - 51).</strong> Each of these sets of action indices corresponds to playing either 1, 2, 3, or 4 of a card of rank 0 - 12 (2 - Ace).</li>
  <li><strong>Action Index (52-64).</strong> These actions correspond to playing a card of rank 0 - 12 from the player’s face up pile.</li>
  <li><strong>Action Index (65-77).</strong> These actions correspond to playing a card of rank 0 - 12 from the player’s face down pile.</li>
  <li><strong>Action Index 78.</strong> This action corresponds to picking up the pile.</li>
</ol>

<p>The neural net has the opportunity to pick any of these actions, no matter the conditions imposed upon it by the available cards in its hand or the top card of the discard pile. <em>However</em>, the conditions are imposed by a masking vector. This masking vector imposes the game logic on the vector of possible outputs from the neural net. That logic is shown below:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">get_valid_mask</span><span class="p">(</span><span class="n">hand</span><span class="p">,</span> <span class="n">discard_pile</span><span class="p">,</span> <span class="n">face_up_pile</span><span class="p">,</span> <span class="n">face_down_pile</span><span class="p">):</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">6</span><span class="p">,</span> <span class="mi">13</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>
    
    <span class="c1"># Check if the player possess each rank in any pile
</span>    <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">13</span><span class="p">):</span>
        <span class="c1"># Hand play (1-4 cards)
</span>        <span class="k">for</span> <span class="n">num_cards</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">hand</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">num_cards</span><span class="p">:</span>
                <span class="n">mask</span><span class="p">[</span><span class="n">num_cards</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">rank</span><span class="p">]</span> <span class="o">=</span> <span class="bp">True</span>

        <span class="c1"># Face-up play (Only if hand is empty)
</span>        <span class="k">if</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">hand</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">face_up_pile</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">mask</span><span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="n">rank</span><span class="p">]</span> <span class="o">=</span> <span class="bp">True</span>

        <span class="c1"># Face-down play (Only if hand and face-up are empty)
</span>        <span class="k">if</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">hand</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">face_up_pile</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">face_down_pile</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">mask</span><span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="n">rank</span><span class="p">]</span> <span class="o">=</span> <span class="bp">True</span>

    <span class="n">mask_pickup</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">discard_pile</span><span class="p">.</span><span class="n">cards</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span>

    <span class="c1"># discard pile restrictions
</span>    <span class="k">if</span> <span class="n">mask_pickup</span><span class="p">:</span>
        <span class="n">top_card</span> <span class="o">=</span> <span class="n">discard_pile</span><span class="p">.</span><span class="n">cards</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

        <span class="c1"># check for three first
</span>        <span class="k">if</span> <span class="n">top_card</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">13</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">rank</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">mask</span><span class="p">[:,</span> <span class="n">rank</span><span class="p">]</span> <span class="o">=</span> <span class="bp">False</span>

        <span class="k">else</span><span class="p">:</span> <span class="c1"># normal restrictions
</span>            <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">13</span><span class="p">):</span>
                <span class="n">is_wild_card</span> <span class="o">=</span> <span class="p">(</span><span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">or</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">5</span> <span class="ow">or</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">8</span><span class="p">)</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">is_wild_card</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">top_card</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span> <span class="c1"># 2 is on top
</span>                        <span class="k">break</span> <span class="c1"># Everything already True from possession check stays True
</span>                    <span class="k">elif</span> <span class="n">top_card</span> <span class="o">==</span> <span class="mi">5</span><span class="p">:</span> <span class="c1"># 7 is on top
</span>                        <span class="k">if</span> <span class="n">rank</span> <span class="o">&gt;=</span> <span class="mi">6</span><span class="p">:</span> 
                            <span class="n">mask</span><span class="p">[:,</span> <span class="n">rank</span><span class="p">]</span> <span class="o">=</span> <span class="bp">False</span>
                    <span class="k">elif</span> <span class="n">rank</span> <span class="o">&lt;</span> <span class="n">top_card</span><span class="p">:</span>
                        <span class="n">mask</span><span class="p">[:,</span> <span class="n">rank</span><span class="p">]</span> <span class="o">=</span> <span class="bp">False</span>

    <span class="c1"># Flatten and add the pickup action (Index 78)
</span>    <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">mask</span><span class="p">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">mask_pickup</span><span class="p">).</span><span class="n">astype</span><span class="p">(</span><span class="nb">bool</span><span class="p">)</span>
</code></pre></div></div>

<p>While this imposes restrictions on the possible actions that the neural net is able to take, it is up to a function with the game environment to determine the results of these actions. For example, while it is possible for the neural net to play any one of its face down cards, it is forced to make a random decision since it should not know what cards it has.</p>

<h1 id="how-is-the-neural-net-making-its-decision">How is the neural net making its decision?</h1>

<p>The input vector fed into this neural net is given as follows:</p>

<ol>
  <li><strong>Last Actions (0 - 12), (13 - 25), (26 - 38).</strong> Each set of indices corresponds to the last three actions taken to the discard pile (where (0 - 12) is the most recent action.) Each rank can be populated by a number 1 through 4 representing the number of cards of that type that were put down. Including this information in the input vector allows the neural net to access some memory of how the game has been played up until the current turn.</li>
  <li><strong>Current Hand (39-51).</strong> Each index corresponds to the rank available in the player’s hand with a number 0 - 4 representing how many of that rank they have in their hand.</li>
  <li><strong>Valid Mask (52-131).</strong> Each index corresponds to the mask as described above.</li>
</ol>

<p>Using this input vector, the neural net generates a vector of probabilites for each action that it wants to take in the form of its output vector. These outputs are masked by the valid mask, the choice is made, positive and negative rewards are calculated for the choice, and the turn passes onto the next player.</p>

<p>At the end of the game the rewards for each turn are aggregated and discounted based on their distance from the end of the game. Loss is calculated from the normalized returns that the player gets from these rewards (in combination with an entropy factor) and this loss is backpropagated through the neural network. Integrated into this loss is the valid mask that was used to help the player make the legal decision. As a result, during backpropagation, the neural net is predisposed to learning not to make an illegal move very quickly.</p>

<h1 id="the-training-scheme">The training scheme.</h1>

<p>Because Palace is a game influence by random chance as well as strategy, it is important to use batching of games played so that the neural net isn’t influenced by an extremely lucky or extremely unlucky game. The batch is set to a relatively small number here, either 8 or 16 games. Only after a batch of games is played, the total loss and its backpropagation will be calculated for each neural net.</p>

<p>A generation will consist of 10 times the number of games in a batch. After a generation, the neural nets engage in a “tournament” to decide who the best player is. During this tournament losses (where a player is the last one left with cards) are recorded over games in the amount of 20 times the number of players. In order to make the training more stable, I made it hard to overthrow the best player (the king) and easy to remain the king. This means that if the king loses less than or equal to it’s equal share of games (20) it remains the king. Additionally, even if it loses more than 20, if no other player loses less than 15 games, it still keeps its title.</p>

<p>After the tournament, the king neural net has its weights saved so that for the next generation it remains static and plays with the other learning nets. This means that each learning net is always playing against the current best neural net and learning a strategy to beat them.</p>

<h1 id="next-steps">Next steps!</h1>

<p>I want these players to be able to beat even the most experienced Palace player. In order to do so, I plan to do the following things:</p>

<ol>
  <li><strong>Increase Network Complexity.</strong> Right now, the network is a fairly simple feed forward network. While this may be enough to learn a small amount of strategy, it might not allow the network to learn effective strategies for the different stages of the game. Additionally, integrating a structure like a (Long Short Term Memory) LSTM component might help the neural net keep track of what the other players have in their hands without actually seeing their current hand.</li>
  <li><strong>Make Changes to the Input Vector.</strong> Right now, the neural net can not see what the other players have in their face-up piles. This should be a part of the input vector so that the neural net knows not to let them be able to place cards from this pile to easily.</li>
  <li><strong>Refine the reward system.</strong> Right now, rewards are doled out based only on my ideas of what good and bad moves might be in the game and how good or bad they might be. However, this is the key to effective learning for this training scheme. It will be important to refine the weights given to the different kinds of decisions the neural net makes.</li>
</ol>

<h1 id="can-you-beat-these-players">Can you beat these players?</h1>

<p>It’s easy to play the game! Download the python files <a href="https://github.com/ma-casali/palace-ai">here</a> and you can run a game from your terminal using the pre-saved weights or you can retrain the AI yourself!</p>

<p>Here’s an example of what the first turn in a game can look like:</p>

<p><img src="/assets/images/PalaceAIGameScreenshot.png" alt="Palace Game Screenshot" /></p>


  </div><a class="u-url" href="/projects/palace-ai/" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">Matthew Casali</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Matthew Casali</li><li><a class="u-email" href="mailto:casali.ma98@gmail.com">casali.ma98@gmail.com</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/ma-casali"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">ma-casali</span></a></li><li><a href="https://www.linkedin.com/in/matthew-casali-761158133"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#linkedin"></use></svg> <span class="username">matthew-casali-761158133</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>I am an acoustic engineer that focuses on hardware development, real-time DSP, and machine learning among other random projects!</p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
